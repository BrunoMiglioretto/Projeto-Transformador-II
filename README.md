# Projeto-Transformador-II â€” README de Artefatos, Resultados e Reprodutibilidade

> **Escopo:** classificaÃ§Ã£o em imagens para os atributos `upper_color`, `lower_color`, `gender`, `bag` e `hat` do dataset **PAR2025**. Os experimentos avaliaram arquiteturas **EfficientNet-B0**, **MobileNetV2** e **SwinV2-T**, com e sem **transfer learning**, e com **data augmentation**.

## Resultados dos Experimentos

Devido ao tamanho dos arquivos de saÃ­da â€” especialmente os **pesos dos modelos (`.pth`)**, figuras de treinamento e matrizes de confusÃ£o â€”, os resultados completos **nÃ£o foram incluÃ­dos diretamente neste repositÃ³rio**, uma vez que o GitHub impÃµe um limite de **100 MB por arquivo** e **2 GB por pacote de push**.

Todos os **artefatos experimentais completos** (modelos, relatÃ³rios CSV e grÃ¡ficos) estÃ£o disponÃ­veis no seguinte link pÃºblico:

> ðŸ“‚ **[Acesse aqui os resultados completos no Google Drive](https://drive.google.com/drive/folders/1MN4NYTUKyvus_9fwL0zg_hl0edMl5mJh?usp=sharing)**

**ConteÃºdo do link:**

* Checkpoints dos modelos (`best_model.pth`) treinados em cada configuraÃ§Ã£o (com/sem transfer learning, com/sem data augmentation).
* GrÃ¡ficos de acurÃ¡cia e matrizes de confusÃ£o por arquitetura e tarefa.
* RelatÃ³rios consolidados (`general_summary_report.csv` e `ensemble_summary_report.csv`).
* Logs de treinamento (`terminal_output.txt`) e parÃ¢metros utilizados.

> **ObservaÃ§Ã£o:** os arquivos `.pth` e demais saÃ­das sÃ£o grandes (~100 MB cada) e foram movidos para o Google Drive apenas para **garantir reprodutibilidade** e **armazenamento persistente**, conforme prÃ¡ticas comuns em projetos de Deep Learning.

---


## 1\) Estrutura de pastas (nÃ­vel superior)

  * `analysis/`

      * **`par.ipynb`**: notebook de exploraÃ§Ã£o, preparaÃ§Ã£o, treino/avaliaÃ§Ã£o e anÃ¡lise do **PAR2025**.
        **PrÃ©-requisitos:** `./data/PAR2025/training_set.txt` e `./data/PAR2025/validation_set.txt` (gerados pelo `download_datasets.py`).
        **SaÃ­das tÃ­picas:** figuras de curvas/discordÃ¢ncias e tabelas consolidadas (salvas em `plots/` e `modelos/{...}/general_summary_report.csv`).

  * `data_agumentation/`

      * **`data_agumentation-50-50.py`**: script de *data augmentation* com polÃ­tica **50/50** (gera amostras **apenas** para a classe minoritÃ¡ria de cada atributo binÃ¡rio, atÃ© equilibrar \~50/50). Centraliza transformaÃ§Ãµes usadas durante os treinos experimentais.
        **Como usar:** nÃ£o recebe CLI; **edite os parÃ¢metros** no topo do arquivo (ex.: `BASE_PATH`, `TRAIN_CSV_PATH`, `SAVE_DIR`, `SAMPLE_PERCENTAGE`, `TRANSFORMATION_TYPE = {SIMPLE|COMPLETE}`, `RANDOM_SEED`).
        **O que ele faz:**
          * LÃª o CSV de treino e cria um **dataset balanceado** (gera imagens sintÃ©ticas com `torchvision.transforms`).
          * Salva **apenas as sintetizadas** em `.../augmented_only/` e **todas** (originais + sintetizadas) em `.../all_images/`.
          * Exporta **CSV final** com caminhos atualizados (`dataset_balanceado_amostra.csv`) e **grÃ¡ficos** de distribuiÃ§Ã£o antes/depois.

  * `modelos/`

      * **`BASELINE-com_transfer_leaning/`**: resultados dos treinos **com** transferÃªncia de aprendizado (pesos prÃ©-treinados). Estruturado por **tarefa** (`bag/`, `gender/`, `hat/`, `lower_color/`, `upper_color/`) e, dentro de cada tarefa, por **arquitetura** (`EfficientNet-B0/`, `MobileNetV2/`, `SwinV2-T/`). Cada arquitetura contÃ©m:

          * `accuracy_plot.png`: curva(s) de acurÃ¡cia por Ã©poca (treino/val).
          * `confusion_matrix.png`: matriz de confusÃ£o no conjunto de validaÃ§Ã£o/teste (conforme configurado).
          * `terminal_output.txt`: *stdout* completo do treino (Ã©pocas, mÃ©tricas, tempos, etc.).

      * **`BASELINE-sem_transfer_learning/`**: mesma estrutura acima, porÃ©m **sem** pesos prÃ©-treinados (treino do zero).

      * **`output-com_transfer_learning-DataAgumentationDuranteTreinamento/`**: saÃ­das adicionais de experimentos **com transfer learning** + **data augmentation aplicada em tempo de treino**. MantÃ©m o mesmo padrÃ£o por tarefa/arquitetura (figuras, checkpoints e logs).

      * **`output-sem_transfer_learning-DataAgumentationDuranteTreinamento/`**: saÃ­das equivalentes **sem transfer learning** + **data augmentation durante o treino**.

      * **`ensemble_summary_report.csv`**: tabela-resumo com mÃ©tricas agregadas por **ensembles** (hard/soft voting).

      * **`general_summary_report.csv`**: tabela-resumo **geral** por execuÃ§Ã£o (tarefa, arquitetura, *seed*, *augmentation*, acurÃ¡cia, F1, *loss* mÃ­nima, Ã©poca do melhor, etc.).

      * **`train_models.py`**: *runner* principal de treinamento (varre tarefas e arquiteturas).
        **Entradas esperadas:** `--data-root PATH` apontando para o diretÃ³rio que contÃ©m `training_set.txt` e `validation_set.txt` (ex.: `./data/PAR2025`).
        **ParÃ¢metros (linha de comando):**

          * `--data-root PATH` â†’ raiz do dataset (obrigatÃ³rio).
          * `--epochs INT` â†’ nÃºmero de Ã©pocas (padrÃ£o do script: 10).
          * `--no-pretrained` â†’ **desativa** transfer learning (por padrÃ£o, **usa** pesos prÃ©-treinados).
            **PadrÃµes internos (editÃ¡veis no arquivo):** `IMG_SIZE=200`, `BATCH_SIZE=32`, `LEARNING_RATE=1e-4`, `RANDOM_STATE=42`, `MODELS_TO_TRAIN=['MobileNetV2','EfficientNet-B0','SwinV2-T']`.
            **PrÃ©-processamento:** normalizaÃ§Ã£o ImageNet; treino com `RandomResizedCrop`, `HorizontalFlip(0.5)` e `RandomErasing(0.4)`; validaÃ§Ã£o/teste com `Resize`.
            **EstratÃ©gia de *split*:** reparte o arquivo `validation_set.txt` em **val** e **teste** (50/50) **por ID de imagem original** (removendo sufixos `_aug_`).
            **SaÃ­das:**

        <!-- end list -->

        ```
        ./output-{com|sem}_transfer_learning-DataAgumentationDuranteTreinamento/
          {bag|gender|hat|lower_color|upper_color}/{MobileNetV2|EfficientNet-B0|SwinV2-T}/
            â”œâ”€ best_model.pth
            â”œâ”€ accuracy_plot.png
            â”œâ”€ confusion_matrix.png
            â””â”€ terminal_output.txt
          â”œâ”€ general_summary_report.csv
          â””â”€ ensemble_summary_report.csv
        ```

        *(Se rodar o script a partir de `modelos/`, as pastas sairÃ£o em `modelos/output-*`, como na sua Ã¡rvore.)*

  * `plots/`

      * **`gerar_plots_PAR2025.py`**: script utilitÃ¡rio para gerar grÃ¡ficos de distribuiÃ§Ã£o de classes e outras figuras a partir dos **TXTs do PAR2025**.
        **ParÃ¢metros (CLI):**
            **SaÃ­das geradas (no diretÃ³rio corrente):**
          * **`PAR2025_treinamento_colors_distribution.png`** e **`PAR2025_validaÃ§Ã£o_colors_distribution.png`** (cores upper/lower).
          * **`PAR2025_treinamento_gbh_distribution.png`** e **`PAR2025_validaÃ§Ã£o_gbh_distribution.png`** (`gender`, `bag`, `hat`).
   
      * **`PAR2025_treinamento_colors_distribution.png`** e **`PAR2025_validaÃ§Ã£o_colors_distribution.png`**: distribuiÃ§Ã£o de cores (upper/lower) nos conjuntos de treino e validaÃ§Ã£o.
      * **`PAR2025_treinamento_gbh_distribution.png`** e **`PAR2025_validaÃ§Ã£o_gbh_distribution.png`**: distribuiÃ§Ã£o de `gender`, `bag`, `hat` nos conjuntos de treino e validaÃ§Ã£o.

  * `download_datasets.py`
    Script para **baixar/organizar** o conjunto de dados **PAR2025** e os templates de submissÃ£o.
    **ParÃ¢metro (CLI):** `--data-dir PATH` (padrÃ£o: `./data`).
    **O que ele baixa/prepara:**

      * **PAR2025** em `{DATA_DIR}/PAR2025/` (gera os TXTs `training_set.txt` e `validation_set.txt` e organiza imagens).
      * **Templates de submissÃ£o** em `./submission_templates/`.
        **Estrutura criada:**

    <!-- end list -->

    ```
    {DATA_DIR}/
    â””â”€â”€ PAR2025/
    Â  Â  â”œâ”€â”€ training_set/
    Â  Â  â””â”€â”€ validation_set/
    ./submission_templates/
    ```

  * `environment.yml`
    DefiniÃ§Ã£o do ambiente Conda (Python + libs de visÃ£o computacional/ML).
    **Principais dependÃªncias esperadas:** PyTorch/torchvision, scikit-learn, pandas, numpy, matplotlib, Pillow, tqdm, **gdown** (para downloads), e utilitÃ¡rios de leitura de imagens.

-----

## 2\) OrganizaÃ§Ã£o dentro de `modelos/`

**PadrÃ£o de organizaÃ§Ã£o (idÃªntico em todas as variaÃ§Ãµes):**

```
modelos/
â”œâ”€â”€ {VARIANTE}/
â”‚Â  Â â”œâ”€â”€ bag/
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ EfficientNet-B0/
â”‚Â  Â â”‚Â  Â â”‚Â  Â â”œâ”€â”€ accuracy_plot.png
â”‚Â  Â â”‚Â  Â â”‚Â  Â â”œâ”€â”€ best_model.pth
â”‚Â  Â â”‚Â  Â â”‚Â  Â â”œâ”€â”€ confusion_matrix.png
â”‚Â  Â â”‚Â  Â â”‚Â  Â â””â”€â”€ terminal_output.txt
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ MobileNetV2/
â”‚Â  Â â”‚Â  Â â””â”€â”€ SwinV2-T/
â”‚Â  Â â”œâ”€â”€ gender/
â”‚Â  Â â”œâ”€â”€ hat/
â”‚Â  Â â”œâ”€â”€ lower_color/
â”‚Â  Â â”œâ”€â”€ upper_color/
â”‚Â  Â â”œâ”€â”€ ensemble_summary_report.csv
â”‚Â  Â â””â”€â”€ general_summary_report.csv
â””â”€â”€ train_models.py
```

Onde `{VARIANTE}` $\in$ {`BASELINE-com_transfer_leaning`, `BASELINE-sem_transfer_learning`, `output-com_transfer_learning-DataAgumentationDuranteTreinamento`, `output-sem_transfer_learning-DataAgumentationDuranteTreinamento`}.

**Arquivos por arquitetura (em cada tarefa):**

  * **`best_model.pth`**: checkpoint com os melhores pesos.
  * **`accuracy_plot.png`**: desempenho por Ã©poca (treino/val).
  * **`confusion_matrix.png`**: erros/acertos por classe.
  * **`terminal_output.txt`**: log literal da execuÃ§Ã£o (hints de parÃ¢metros, lr, tempos, etc.).

**RelatÃ³rios CSV:**

  * **`general_summary_report.csv`**: uma linha por execuÃ§Ã£o (tarefa $\times$ arquitetura $\times$ variaÃ§Ã£o), com mÃ©tricas-chave e metadados.
  * **`ensemble_summary_report.csv`**: agregaÃ§Ãµes/combinaÃ§Ãµes quando aplicÃ¡vel (mÃ©dias, *voting*, *stacking*, etc.).

-----

## 3\) Como reproduzir

1.  **Criar ambiente** (Conda):

    ```bash
    conda env create -f environment.yml
    conda activate projeto-transformador-ii
    ```

2.  **Baixar dados** (PAR2025 e templates):

    ```bash
    python download_datasets.py --data-dir ./data
    ```

3.  **Executar treinamentos**:

      * **Com transfer learning (padrÃ£o):**

        ```bash
        python modelos/train_models.py \
          --data-root ./data/PAR2025 \
          --epochs 10
        ```

      * **Sem transfer learning (treino do zero):**

        ```bash
        python modelos/train_models.py \
          --data-root ./data/PAR2025 \
          --epochs 10 \
          --no-pretrained
        ```